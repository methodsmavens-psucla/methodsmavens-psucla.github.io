[
  {
    "path": "posts/2021-12-13-r-bootcamp-4-functions-in-r/",
    "title": "R Bootcamp #4: Functions in R",
    "description": "An introduction to basic R functions, data types, and structures",
    "author": [
      {
        "name": "Ciara Sterbenz",
        "url": {}
      }
    ],
    "date": "2021-11-29",
    "categories": [
      "bootcamp"
    ],
    "contents": "\n\nContents\nFunctions in RVideo Walk through\nConceptually, what are functions? What are they good for anyway?\nBasic Syntax with FunctionsDigging into the Details:\n\nFunctions and “Scope”\nDebuggingPrinting\n\nPower in Infinite Flexibility\n\n\nFunctions in R\nHello again! Today we’re going to dive into the idea of functions in coding. Functions are a fundamental building block in coding generally, and you’ve already encountered and used many of them written by others (e.g. dpylr::select(), base::mean()etc). Today we’ll discuss why they are so useful, how they work, and how to write and use your very own functions!\nVideo Walk through\n\n\nConceptually, what are functions? What are they good for anyway?\nGenerally, a function does all the regular coding you’re used to but is built using abstract, general data structures rather than with concrete (locally-loaded/stored) data. What does this mean? In brief, a function is a shell of code that is written in general terms and by itself does do anything or manipulate any data until we later “run it.” When we write a function, we are actually telling the computer to store the code that we write in memory for later use. For example:\nThis makes functions really convenient for repeated use when we want to do the same basic thing many times, typically also with different data. Instead of copy-pasting the same code over and over, we can simply re-run a function over and over. This is both easier to follow and read, and more “safe” in terms of avoiding mistakes. A general rule of thumb in coding is that if you have to copy-paste any significant portion of code to do something two or more times, you’re better off just building a function and running it twice! This is good coding practice for two reasons: first, it actually saves you time in the long run (it may seem unneccesary and difficult at first but the more practice you get the more use you’ll see for it), and second, it saves you from your own silly mistakes when copy-pasting. You’d be amazing at how easy it is cause yourself all kind of headaches simply because you accidentally wrote over an object you needed by accident, mislabel something, or forget to change some small part of the code when copy-pasting. You lose a lot of time (and sanity) tracking down these small mistakes because they often don’t actually produce any code errors, just wrong answers.\nBasic Syntax with Functions\nAnything in R that has ...() is a function. For example, when we type test() we are indicating to R that ‘test’ is a function it should already know about and we want it to now run that function. If we were to type just test on the other hand, we would be indicating to R that ‘test’ is an object, an actual piece of computer memory that stores some data.\n\n\n#since I have not told R what \"test\" or \"test()\" may be both of these lines cause an error\n#you can see from the error messages how \"()\" changes R's expectations\ntest\n\n\nError in eval(expr, envir, enclos): object 'test' not found\n\ntest()\n\n\nError in test(): could not find function \"test\"\n\nThe general structure of all functions is the following:\n\n\nmy_function <- function(arguments) {\n    #fill in your genius code here \n    return(output)\n}\nmy_function\n\n\n\nFirst let’s just break down each component and then below I’ll give you some more specific things to keep in mind. First on the left we have the nam\nmy_function - Function’s Name: just as with objects, we give a function a name so we can later refer back to it. In the above example, I’ve very creatively named it “my_function”.\nmy_function <- function(...) {} - this tells R that the object my_function will be a function. You can see from the handy-color coding in your text editor that both the function() and return() language are somewhat special. This syntax is specially reserved in R to contstruct functions and all functions that you write must have this structure. Elements inside the paratheses function(...) are referred to as inputs or arguments of the function - they are the data you “pass in” for the function to work with. Everything inside the following brackets {}forms the the shell code that the function will perform when it is later called.\nreturn(...) - this tells R what to “return” from the function. In other words, when we run the function what does it give us back?\nDigging into the Details:\n1. Calling vs Declaring a Function\nFunctions are always a two stage process. First, we “declare the function,” writing out the function contructor syntax and filling in all the code we want the function to perform, then itializing the function by running this constructor code. At this stage all we are doing is telling R to save to memory the contents of your function. It WILL NOT run/evaluate any of the internal code at this stage. Here we are simply writing the basic shell that we will use later. The second stage is where we “call the function.” This is where we actually ask R to run the code inside the function and thus where we would need to supply the arguments (that do not have a default, more on this below) in order for things to work.\nWhat does this mean practically? If you have any errors, R will not find them until you call the function and try and run it on actual data! Additionally, if you edit your function in any way, you must declare it again (rerun the constructor code) for R to know you made any changes (we have to resave the code it associates with object that is our function name).\n\n\n#let's say I have a typo and write \"frist\" inside the function, instead of \"first\" \n#since R has no idea what \"frist\" is, this will produce an error\n#but just establishing the function and running the following reports no errors !\n# why? because R has not actually evaluated the code\nbroken <- function(first, second) {\n    sum <- frist+second\n    return(sum)\n}\n#when we actually call the function however, it complains that it has no idea what \"frist\" is\nbroken(3,2)\n\n\nError in broken(3, 2): object 'frist' not found\n\n2. Arguments - input data for the function to use\nMost functions require some input data that they’ll use internally. Others may not require any inputs. For example “Sys.time()” doesn’t need any data to tell you what time it is. When arguments are written without a “default” they are mandatory and the function will not run without them. For these arguments, R is expecting some form of input data and will immediately halt if it doesn’t recieve it when the function is called. On the other hand, we can set arguments with a default when we set up the function such that the function will proceed when called even without any inputted data using the default value. Of course, the user can always overwrite a default in “function call,” meaning that any the argument passed in when the function is called will always trump the default.\nNote that in R you do not specify what type/class of data these arguments will be unlike some other languages. This enables great flexibility! An example is near the end of this post.\n\n\n#I set x to have a default of 4\n#I have set y to have no default\n#this function \"returns\" or gives back to the user simply the sum of x and y\nex_1 <- function(x = 4, y) {\n    out <- x+y\n    return(out)\n}\n#because I do not tell it what y is going to be it gives me an error\nex_1()\n\n\nError in ex_1(): argument \"y\" is missing, with no default\n\n#when I do not tell it what x is, it's no problem however! just uses default x = 4\nex_1(y = 1)\n\n\n[1] 5\n\n#i can always overwrite a default directly in the \"function call\"\nex_1(x = 0, y = 1)\n\n\n[1] 1\n\n#some functions have no inputs\nSys.timezone()\n\n\n[1] \"America/Los_Angeles\"\n\nArguments can be “passed in” to a function by position/order or by name. Passing in arguments by order allows you to avoid a little typing when “calling the function” (running it). Instead of fully typing out the names of each of the functions arguments, you can pass in data directly according to the order specified in when the function was declared and R will rely the order of the arguments to figure out what inputted data refers to what function argument.\n\n\n#this funciton returns simply the fraction of the first over the second argument\nex_2 <- function(first, second) {\n    return(first/second)\n}\n#passing in based on order assumes first = 1, second = 3\nex_2(1,3)\n\n\n[1] 0.3333333\n\nex_2(3,1)\n\n\n[1] 3\n\nAlternatively, you can always use the name of the arguments to clearly tell R what refers to what. This might be a tad more typing, but it also allows you to not worry about remembering what the correct order should be.\n\n\n#passing in based on name\n#most intuitively:\nex_2(first = 1, second = 2)\n\n\n[1] 0.5\n\n#but this also works,\nex_2(second = 2, first = 1)\n\n\n[1] 0.5\n\n3. Outputs\nFunctions always “return” some “outputs/values”. This is very general - you can return anything from a simple number all the way to a very complex plot and you can return as many objects as you want of whatever type! This is the real power of a function - we can get a bunch of coding done all in one nice clean chunk and return back all kinds of results all at onee time.\nIn general, it is good coding practice to explicitly state what to return using return(...). That said sometimes you may see functions that don’t have an explicit return statement. R is kind enough to assume that it should return the most recently computed object (the last line), but this is poor coding practice (most other languages would not let you do this). I really don’t recommend skipping the explicit return statement. For readability of your code and to avoid any confusion between what R does for you and what you want it to do, just stick with return()\nIn R, if you want to return multiple objects, you must wrap them inside a list object. Notice that naming the elements of your list will enable you to use the more convenient $ syntax rather than the gross [[...]][...] of lists.\n\n\n#nicely labeled means i can access the different results using $\nex_3 <- function(a, b, c) {\n    sum <- a+b+c\n    frac <- (a+b)/c\n    out <- list(sum = sum, \n                fraction = frac)\n    return(out)\n}\ntest <- ex_3(1,1,2)\nclass(test)\n\n\n[1] \"list\"\n\ntest$fraction\n\n\n[1] 1\n\ntest$sum\n\n\n[1] 4\n\ntest\n\n\n$sum\n[1] 4\n\n$fraction\n[1] 1\n\n#more lazy now, means more headache in the [[]][] indexing later :(\nex_3 <- function(a, b, c) {\n    sum <- a+b+c\n    frac <- (a+b)/c\n    return(list(sum,frac))\n}\ntest <- ex_3(1,1,2)\nclass(test)\n\n\n[1] \"list\"\n\ntest\n\n\n[[1]]\n[1] 4\n\n[[2]]\n[1] 1\n\ntest[[1]]\n\n\n[1] 4\n\nHere’s an example of how R will take the last line of your code as your intended output if you do not explicitly state it. Again, I wouldn’t recommend this, but you may sometimes see others do it.\n\n\n#note that if i do not explictly write a return statement we get the last line of code\nfrac <- function(A,B) { \n    #we can add code here that R will run, but it will not output because it is not returned!\n    A+B\n    #if we don't use return R will assume the last line of code is what we want\n    A/B\n}\nfrac(6,7)\n\n\n[1] 0.8571429\n\n#note also the vector-friendly format of R:\n#we can also easily ask for:\nfrac(A = 4, B = c(1,2,3))\n\n\n[1] 4.000000 2.000000 1.333333\n\n#or\nfrac(A = c(1,2,3), B = c(1,2,3))\n\n\n[1] 1 1 1\n\nA Deeper Dive into the Need for List Outputs\nThe basic reason for having to wrap everything in a list, is beyond your current need-to-know level of comp-sci, but if you’re interested, the basic reason is as follows: computers require data assigned to the same piece of memory to be of the same type. This means that you can not save both a number and a character to the same piece of data (you might recall R will just turn the number into a character so they match). This is an issue for functions because they return a single object that is associated with a single piece of computer memory. So if you want your function to output data of different types, what do you do?! Enter lists to save the day! Recall that list objects allow you to combine all different types of data in one object. The way they do this is by actually saving each data type to separate piece of memory so they can stay different types, but then saving the pointers (locations) to each of these separate objects in the list object the same piece of memory. Since pointers are all of the same type, we can save them all together!\n4. Namespace\nIn fancy codespeak, we refer to the name of a function as its “namespace.” Because R is very flexible, it will allow you to write directly over almost anything you want. You should thereofre be careful not to overwrite the “namespace” of standard/commonly used functions. In other words, there is nothing preventing you from doing the following:\n\n\nex <- c(5, 4)\n#standard base R mean function returns the mean of a vector\nmean(ex)\n\n\n[1] 4.5\n\nmean <- function() {\n    return(\"Don't do this!\")\n}\nmean()\n\n\n[1] \"Don't do this!\"\n\n#and this will now produce an error because R thinks \"mean()\" takes NO arguments/inputs\nmean(ex)\n\n\nError in mean(ex): unused argument (ex)\n\n#we can save ourselves by clearly indicating the namespace by telling R what\n#package/environment to look in... but this is bad just don't do it\nbase::mean(ex)\n\n\n[1] 4.5\n\nAnother thing to note quickly is that all packages are just someone else’s function that you are loading into your own environment! You can now understand some common warning you have perhaps encountered when loading packages.\n\n\n#now we can understand these warnings!\nlibrary(dplyr)\n\n\n\n“The following objects are masked from package:…” indicates that you just loaded a package that has a function with the same namespace! R somewhat infamously has a lot of older packages that supply functions of the same name, but that do totally different things. For example when we load dplyr, we are told “filter” and “lag” are masked from “package:stats.” In other words,dpylr has a function, dplyr::filter, that is writing over the function stats::filter. Sometimes, you may also encounter error messages where R is clearly confused about which function it should be using because they both have the same name. To clarify which namespace you are referring to you can use the following syntax: packagename::functionname(). This may happen annoyingly frequently for dplyr::select unfortunately.\nFunctions and “Scope”\nThe last step to understand functions requires diving a bit into the weeds, but bear with me. Let’s back up a little bit: recalling our basics, we learned we can that in code, we “initialize” an object by telling the computer we will use some name, say “x” or “my_dataframe” etc to refer back to some particular amount computer memory that will store a type of data among the fundamental data types. For us in R you will nearly always be working with logical (often called boolean), numeric (decimal or whole), character (often called string). In more traditional forms of coding, code is written and understood in a hierarchical structure, with different levels that expand upward and build on those below, like a russian-doll. In these languages, when we initialize data, the computer therefore also needs to be told how “accessible” this data is - at what level is the object accessible? only the current level, or above it at the higher, more expanded levels? This is referred to as “scope” - the “scope” of an object is where it is defined/accessible.\nIn R, we (thankfully) do not use this hierarchical structure! So if this is a little confusing fear not! Instead nearly everything is “globally defined.” This mean that the object is the “global environment,” meaning it’s accessible everywhere and we don’t have to worry about any of this heirarchical business and different permissions to use different objects. The downside of this is that it’s very easy to write over something later on in your code without realizing it. For example, on line 15 you may use “x” to refer to a big vector of data and then accidentally later on line 142 you again use “x” to refer to just the number 4, and now you’ve written over your big vector of data and lost it. Having everything globally defined in R is therefore a double edged sword - it saves a lots of pain when declaring data and setting things up, but it can lead to careless mistakes that are a big headache.\nSo why does this matter for functions? Functions are one of the very few places in R where scope actually comes into play and things are NOT globally defined anymore. Instead, the scope of all the code internal to a function (so everythign inside the brackets {}) is limited to the function itself. More concretely for example, if inside a funciton I declare a variable “my_var”, I run the function, and then try and use “my_var” outside the function, R will immedaitely complain it has no idea what “my_var” is. This variable was defined inside the fucntion and its scope is limited to the funciton, it is not accessible or knwon beyond the internals of the function. This is beneficial because it means we can run functions and use names inside of it that may be the same as ones we outside the function (globally), but we will not overwrite our original objects!\nIt’s super important to understand the scope of functions to understand how they work and how you can use them. You will not be able to access any data from inside the function unless you pass it out specifically!\n\n\n#globally defined x\nx <- 4\nx\n\n\n[1] 4\n\n#now what happens if i try and write-over x inside a function?\ntest_scope <- function() {\n    x = 6\n    internal_only = \"won't see the light of day\"\n    return(x)\n}\n#returns 6 as expected\ntest_scope()\n\n\n[1] 6\n\n#did I write over x?? No! hurrah\nx\n\n\n[1] 4\n\n#I only write over x if i do so explicitly in the global environment\nx <- test_scope()\nx\n\n\n[1] 6\n\n#does R know what internal_only is? Nope! \n#even though it was created by the function when i ran it,\n#it's lost forever because i did not return it\ninternal_only\n\n\nError in eval(expr, envir, enclos): object 'internal_only' not found\n\nHowever… I am compelled to also point out that in R though what a function does internally is not accessible in the global environment (e.g. i can’t access internal_only outside the function), the reverse is not true. Functions can access and use what is in the global environment (though as we saw it can not write over objects in the global environment). This is a bit of a quirk in R and would not work in more strictly hierarchical languages. What does this mean practically? You can write a function that uses a global variable that is not passed in as an argument! This, however, is generally very poor coding practice. Why? If the globally defined variable is removed or changes value, the output of the function will change or not even run. And yet, we changed nothign about the function itself! This type of inconsistency is highly vulnerable to user-error and is dangerous for that reason. I’d say it should pretty much always be avoided. (Only in advance use cases where functions are nestsed within eachother would I recommend ever doing this)\n\n\n#globally define my_var\nmy_var <- 1234\n\nbad_ex <- function(w) {\n    #i can still access my_var inside the functino even though it wasn't passed in!\n    prod = w*my_var\n    return(prod)\n}\n#this will still run no problem :O\nbad_ex(w = 1)\n\n\n[1] 1234\n\n#now i go code 100 more lines and at somepoint redefine my_var\nmy_var = 12\n#and i run my exact same code as before, nothing about the function has changed]\n#but i get a different answer \nbad_ex(w = 1)\n\n\n[1] 12\n\n#even worse,i removed my_var from the global environmnet the function breaks entirely\nrm(my_var)\nbad_ex(w=1)\n\n\nError in bad_ex(w = 1): object 'my_var' not found\n\nDebugging\nThis brings us to debugging. Debugging within a function might seem difficult at first because when we declare the function, R does not evaluate the internal code and will not find any errors. However, when we do later call the function and run the internal code, we don’t get to see R go line by line, making it quite hard to see where things broke down when we run into errors. Typically If you get an error, but can’t tell what’s causing it and then go back inside the function to try to run any of the internal code on its own that uses the functions arguments, R will complain that it doesn’t know what data you’re using since you didn’t pass it in! Yikes… So how to debug a function?\nTypically, the approach is to run the internal code of the function yourself line by line to find the issue. In order for this to work, you will of course need to initialze the arguments because otherwise R will have no idea what they are. I recomend explicitly initializing them inside the function at the very top. By doing this, you’re actually making everything global! This allows you to find where issues are, but also means you’ve just stored all the code and objects internal to the function to the global environment. Once you’ve fixed the issue, tgherefore, you should therefore remove these objects from the global environment and be sure to remember to delete the lines at the top where you initialized the argument. Otherwise, you’re function will disregard the user-specified arguments every time.\n\n\n################ Debugging\n#so this won't run because \"broken\" tries to use \"C\" before we've declared it\n#but if you just run the function R will not complain!\nbroken <- function(A,B) {\n    sum = A+B\n    prod = A*B\n    broken = A/B - C\n    C = sqrt(A^2 + B^2)\n    return(list(sum = sum, \n                prod = prod,\n                broken = broken,\n                C= C))\n}\n#R only finds the issue when you ask it to actually run the function\nbroken(6,7)\n\n\nError in A/B - C: non-numeric argument to binary operator\n\n#this error mesage is a little opaque and let's say \n#it is not immediately obvious to you what went wrong, what to do? \n#if you try to run line by line within the function:\n#R will complain that it has no idea what A and B are\n#So go back inside your function and direcly declare A and B \n#then test your code\nbroken <- function(A,B) {\n    # XXXX REMINDER DELETE LATER  AND RM FROM EVIVORNMENT\n    A = 1; B = 2\n    #now R knows what A and B are and we can run the following lines internally\n    sum = A+B #good\n    prod = A*B #good\n    C = sqrt(A^2 + B^2) \n    broken = A/B - C # ah ha we found the problem!\n    return(list(sum = sum, \n                prod = prod,\n                broken = broken,\n                C= C))\n}\nbroken(1,2)\n\n\n$sum\n[1] 3\n\n$prod\n[1] 2\n\n$broken\n[1] -1.736068\n\n$C\n[1] 2.236068\n\n\n\n#so now we found the problem you'd fix it and BE SURE TO DELETE the stored inputs\n#both from your environment and from the function code\n#otherwise everytime you run your function it will use what you set internally and ignore the inputs you have \nrm(A, B)\nfixed<- function(A,B) {\n    sum = A+B \n    prod = A*B \n    C = sqrt(A^2 + B^2) \n    broken = A/B - C \n    \n    return(list(sum = sum, \n                prod = prod,\n                broken = broken,\n                C= C))\n}\nfixed(6,7)\n\n\n$sum\n[1] 13\n\n$prod\n[1] 42\n\n$broken\n[1] -8.362402\n\n$C\n[1] 9.219544\n\n#note ofc that if you don't delete those internal inputs though: you're stuck with 6 and 7\ndontdothis<- function(A,B) {\n    A = 6\n    B = 7\n    sum = A+B \n    prod = A*B \n    C = sqrt(A^2 + B^2) \n    broken = A/B - C \n    \n    return(list(sum = sum, \n                prod = prod,\n                broken = broken,\n                C= C))\n}\ndontdothis(5,6) #still gives us the results for 6 and 7!\n\n\n$sum\n[1] 13\n\n$prod\n[1] 42\n\n$broken\n[1] -8.362402\n\n$C\n[1] 9.219544\n\nPrinting\nYou can also help yourself debug by printing things out. This way you can see what the function was doing internally even when it was called. This is especially handy if your function has a long computation time and you want some updates or verification it’s going according to plan.\n\n\n#use either paste() or cat()\n#cat() is nice because it prints out like a warning/error message would without quotes\n#print() prints out as if something is being returned notice the [1]\n#and is a little less clean to use but works just fine\n#not a major difference so do whatever you like\ntestprint <- function(A,B) {\n    #when using cat you need to tell it to start a new line for the next print out using \\n\n    cat(\"cat: A is\", A, \"and B is\", B, \"returning their sum: \\n\")\n    #print is a little uglier because c() turns 6 into a string since all elemnts\n    #of a vector must be the same type (all strings or \"characters\" in R)\n    print(x = c(\"print + c(): A is\",A, \"B is\"))\n    #or cleaning that up a bit by also using paste()\n    print(x = paste(\"print + paste(): A is\",A, \"B is\"))\n    return(A+B)\n}\ntestprint(4,5)\n\n\ncat: A is 4 and B is 5 returning their sum: \n[1] \"print + c(): A is\" \"4\"                 \"B is\"             \n[1] \"print + paste(): A is 4 B is\"\n[1] 9\n\nPower in Infinite Flexibility\nThe real power of functions lies in their infinite flexibility. You can write a function to take in any input and give you any output!\nAs a totally arbitrary example, I can write a function that will take generalized input object x and: - if it is a character, output the number of letters in it - if it is a single number return the log - if it is a vector return the mean and standard deviation - if it is a matrix return its inverse\n\n\nmy_funct <- function(x) {\n    \n    if(class(x) == \"character\") {\n        return(nchar(x))\n    } else if(class(x) == \"numeric\" & length(x) == 1) { \n        #issue 1: anticipate any issues with this?\n        return(log(x))\n    } else if(class(x) == \"numeric\") { \n        #is not character or numeric with length 1, but is numeric (must be vector)\n        return(list(sd = sd(x),\n                    mean = mean(x)))\n    } else {\n        #is none of the above, we assume it's a matrix\n        #issue 2: any possible issues with this?\n        return(solve(x))\n    }\n}\nmy_funct(\"hello there\")\n\n\n[1] 11\n\nmy_funct(4)\n\n\n[1] 1.386294\n\nlog(4)\n\n\n[1] 1.386294\n\nmy_funct(x = c(1,2,3))\n\n\nError in mean(x): unused argument (x)\n\nmy_funct(x = matrix(c(rnorm(9)), nrow = 3, ncol = 3))\n\n\n          [,1]      [,2]       [,3]\n[1,] 0.2585991  1.105319  1.3832767\n[2,] 0.4230802 -1.366480 -1.8314449\n[3,] 0.6919316  1.492746 -0.9682622\n\n#issue 1?\nmy_funct(-1)\n\n\n[1] NaN\n\n#issue 2?\nmy_funct(x = matrix(c(rnorm(12)), nrow = 3, ncol = 4))\n\n\nError in solve.default(x): 'a' (3 x 4) must be square\n\nCongrats you made it to the very end! I encourage you to tinker around and try and write (and also break) your own functions to better understand how they work.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-12-13T18:00:39-08:00",
    "input_file": "r-bootcamp-4-functions-in-r.knit.md"
  },
  {
    "path": "posts/2021-11-17-r-bootcamp-3-summarizing-data-with-the-tidyverse/",
    "title": "R Bootcamp #3 - Summarizing Data with the Tidyverse",
    "description": "An introduction to data manipulation with tidyverse functions",
    "author": [
      {
        "name": "Derek Holliday",
        "url": {}
      }
    ],
    "date": "2021-11-18",
    "categories": [
      "bootcamp"
    ],
    "contents": "\r\n\r\nContents\r\nVideo Summary\r\nWhat is the tidyverse?\r\ndplyr\r\nPiping\r\nselect()\r\nfilter()\r\narrange()\r\nmutate()\r\nsummarise()\r\nacross()\r\n\r\n\r\nTest your knowledge\r\n\r\nWelcome to the first day of the rest of your (coding) life. In the first two sessions, we covered base R functionality, but today we turn to a more “opinionated” R coding philosophy: the tidyverse. If you haven’t already, you should install the tidyverse using the command below:\r\n\r\n\r\ninstall.packages(\"tidyverse\")\r\n\r\n\r\n\r\nVideo Summary\r\n\r\n\r\nWhat is the tidyverse?\r\nThe tidyverse is a collection R packages that share a similar philosophy regarding coding and data manipulation generally. These packages include ggplot2, purrr, dplyr, tidyr, tibble, stringr, readr, and forcats. Hadley Wickham, the creator of many of these packages and Chief Data Scientist at R Studio, has written a manifesto on what he believes to be the core tenants of the tidyverse philosophy, but many of them are fairly technical, so for now I’ll skip them.\r\nAt its core, the tidyverse aims to be a human-friendly approach to making data “tidy.” We call non-tidy data messy. Tidy data has one observation per row and one variable per column. Sounds simple, but like many things in life that is rarely the case. We will cover the core functions of tidy data manipulation below, but know that you can make things as exponentially complicated as you would like. You can load tidyverse functions like this:\r\n\r\n\r\nlibrary(tidyverse)\r\n\r\n\r\n\r\nI should note that you should still learn and be familiar with base R. Not all packages are tidyverse-friendly, and to read other peoples’ code you’ll have to know base R. Additionally, writing functions and packages that depend upon tidyverse functions requires loading the tidyverse into memory, which can be inefficient. Treat this as a tool (a very important one) in your toolbox, but don’t let it be your only one.\r\ndplyr\r\nThe dplyr package sits at the core of tidy data manipulation, and is built around 5 basic functions (there are many others, but you will use these the most often):\r\nselect(): this function subsets your dataset to just the columns of data (variables you want). The base R equivalent would simply be df[,c(vars of interest)]\r\nfilter(): this function subsets the data into just the rows you want to look at. The base R equivalent would be subset() or simply df[c(rows),]\r\narrange(): this function sorts the data by row(s) of your choosing. The base R equivalent is sort()\r\nmutate(): this function adds new variables to your dataframe. The base R equivalent is simply df$newvar or df[,'newvar']\r\nsummarise(): this function allows you to summarise your data in someway; usually used in conjunction with group_by() which allows you to summarise data by some other variable.\r\nThis last one is not a core function but it is super useful:\r\ngroup_by(): this function groups your data according to a variable you give it.\r\nPiping\r\nBefore we work with these functions, you should become familiar with the pipe operator %>%. If you have the most recent version of R installed, there is actually a native (non-tidyverse) pipe operator |>. I will use the former.\r\nPiping helps make your code nice and easy to read, moving us away from base R nesting doll syntax and into something that reads more fluidly:\r\n\r\n\r\nlibrary(palmerpenguins) # Using my favorite toy dataset\r\ndf = penguins # Assign penguins dataframe to df for efficiency\r\n\r\ndf %>% head() # Equivalent to head(df)\r\n\r\n\r\n# A tibble: 6 x 8\r\n  species island    bill_length_mm bill_depth_mm flipper_length_mm\r\n  <fct>   <fct>              <dbl>         <dbl>             <int>\r\n1 Adelie  Torgersen           39.1          18.7               181\r\n2 Adelie  Torgersen           39.5          17.4               186\r\n3 Adelie  Torgersen           40.3          18                 195\r\n4 Adelie  Torgersen           NA            NA                  NA\r\n5 Adelie  Torgersen           36.7          19.3               193\r\n6 Adelie  Torgersen           39.3          20.6               190\r\n# ... with 3 more variables: body_mass_g <int>, sex <fct>, year <int>\r\n\r\nWhat is the pipe actually doing? Taking the first argument and passing it to the first argument in the following function:\r\n\r\n\r\n# this reads take my dataframe called df and show me the first 10 rows of it using head()\r\ndf %>% head(10)\r\n\r\n\r\n# A tibble: 10 x 8\r\n   species island    bill_length_mm bill_depth_mm flipper_length_mm\r\n   <fct>   <fct>              <dbl>         <dbl>             <int>\r\n 1 Adelie  Torgersen           39.1          18.7               181\r\n 2 Adelie  Torgersen           39.5          17.4               186\r\n 3 Adelie  Torgersen           40.3          18                 195\r\n 4 Adelie  Torgersen           NA            NA                  NA\r\n 5 Adelie  Torgersen           36.7          19.3               193\r\n 6 Adelie  Torgersen           39.3          20.6               190\r\n 7 Adelie  Torgersen           38.9          17.8               181\r\n 8 Adelie  Torgersen           39.2          19.6               195\r\n 9 Adelie  Torgersen           34.1          18.1               193\r\n10 Adelie  Torgersen           42            20.2               190\r\n# ... with 3 more variables: body_mass_g <int>, sex <fct>, year <int>\r\n\r\n# it is the same as\r\nhead(df, 10)\r\n\r\n\r\n# A tibble: 10 x 8\r\n   species island    bill_length_mm bill_depth_mm flipper_length_mm\r\n   <fct>   <fct>              <dbl>         <dbl>             <int>\r\n 1 Adelie  Torgersen           39.1          18.7               181\r\n 2 Adelie  Torgersen           39.5          17.4               186\r\n 3 Adelie  Torgersen           40.3          18                 195\r\n 4 Adelie  Torgersen           NA            NA                  NA\r\n 5 Adelie  Torgersen           36.7          19.3               193\r\n 6 Adelie  Torgersen           39.3          20.6               190\r\n 7 Adelie  Torgersen           38.9          17.8               181\r\n 8 Adelie  Torgersen           39.2          19.6               195\r\n 9 Adelie  Torgersen           34.1          18.1               193\r\n10 Adelie  Torgersen           42            20.2               190\r\n# ... with 3 more variables: body_mass_g <int>, sex <fct>, year <int>\r\n\r\nWhenever you see the pipe, say the words “then” in your head. For example, say I wanted to subset my data to just Adelie and Gentoo penguins, then look at only the bill_length_mm and flipper_length_mm columns. In base r, this would look like this:\r\n\r\n\r\ndf[df$species %in% c(\"Adelie\",\"Gentoo\"), c(\"bill_length_mm\", \"flipper_length_mm\")]\r\n\r\n\r\n\r\nIn tidy syntax, we can use pipes (adding an extra step to print the first 10 rows)\r\n\r\n\r\ndf %>%\r\n  filter(species %in% c(\"Adelie\",\"Gentoo\")) %>%\r\n  select(bill_length_mm, flipper_length_mm) %>%\r\n  head(10)\r\n\r\n\r\n# A tibble: 10 x 2\r\n   bill_length_mm flipper_length_mm\r\n            <dbl>             <int>\r\n 1           39.1               181\r\n 2           39.5               186\r\n 3           40.3               195\r\n 4           NA                  NA\r\n 5           36.7               193\r\n 6           39.3               190\r\n 7           38.9               181\r\n 8           39.2               195\r\n 9           34.1               193\r\n10           42                 190\r\n\r\nThis reads: take my dataset called df, then filter by species to only Adelie and Gentoo penguins, then select just two variables of interest (then print the first 10 rows). While this syntax may be “longer”, it is infinitely more readable, makes debugging much easier, and doesn’t require you to keep track of trailing/missing parentheses and/or brackets.\r\nNow we’ll go into each of these functions more in-depth:\r\nselect()\r\nIf you just want to look at certain variable in a dataframe, select() helps you do that. For example, if I just want the penguin body mass, I could use:\r\n\r\n\r\n# Using pipe:\r\ndf %>%\r\n  select(body_mass_g)\r\n\r\n# Same as:\r\nselect(df, body_mass_g)\r\n\r\n# In base R:\r\ndf[,\"body_mass_g\"]\r\n\r\n# Alternatively:\r\ndf$body_mass_g\r\n\r\n\r\n\r\nYou can also select more than one variable, a range of variables, or omit certain variables:\r\n\r\n\r\n# select species and body_mass_g\r\ndf %>% select(species, body_mass_g)\r\n\r\n\r\n# A tibble: 344 x 2\r\n   species body_mass_g\r\n   <fct>         <int>\r\n 1 Adelie         3750\r\n 2 Adelie         3800\r\n 3 Adelie         3250\r\n 4 Adelie           NA\r\n 5 Adelie         3450\r\n 6 Adelie         3650\r\n 7 Adelie         3625\r\n 8 Adelie         4675\r\n 9 Adelie         3475\r\n10 Adelie         4250\r\n# ... with 334 more rows\r\n\r\n# select variables bill_length_mm through flipper_length_mm\r\ndf %>% select(bill_length_mm:flipper_length_mm)\r\n\r\n\r\n# A tibble: 344 x 3\r\n   bill_length_mm bill_depth_mm flipper_length_mm\r\n            <dbl>         <dbl>             <int>\r\n 1           39.1          18.7               181\r\n 2           39.5          17.4               186\r\n 3           40.3          18                 195\r\n 4           NA            NA                  NA\r\n 5           36.7          19.3               193\r\n 6           39.3          20.6               190\r\n 7           38.9          17.8               181\r\n 8           39.2          19.6               195\r\n 9           34.1          18.1               193\r\n10           42            20.2               190\r\n# ... with 334 more rows\r\n\r\n# select everything but year\r\ndf %>% select(-year)\r\n\r\n\r\n# A tibble: 344 x 7\r\n   species island    bill_length_mm bill_depth_mm flipper_length_mm\r\n   <fct>   <fct>              <dbl>         <dbl>             <int>\r\n 1 Adelie  Torgersen           39.1          18.7               181\r\n 2 Adelie  Torgersen           39.5          17.4               186\r\n 3 Adelie  Torgersen           40.3          18                 195\r\n 4 Adelie  Torgersen           NA            NA                  NA\r\n 5 Adelie  Torgersen           36.7          19.3               193\r\n 6 Adelie  Torgersen           39.3          20.6               190\r\n 7 Adelie  Torgersen           38.9          17.8               181\r\n 8 Adelie  Torgersen           39.2          19.6               195\r\n 9 Adelie  Torgersen           34.1          18.1               193\r\n10 Adelie  Torgersen           42            20.2               190\r\n# ... with 334 more rows, and 2 more variables: body_mass_g <int>,\r\n#   sex <fct>\r\n\r\nAdditionally, you can select based on characteristics of the variables names, such as containing “length” or starting with “bill”:\r\n\r\n\r\n# select variables that contain \"length\"\r\ndf %>% select(contains(\"length\"))\r\n\r\n\r\n# A tibble: 344 x 2\r\n   bill_length_mm flipper_length_mm\r\n            <dbl>             <int>\r\n 1           39.1               181\r\n 2           39.5               186\r\n 3           40.3               195\r\n 4           NA                  NA\r\n 5           36.7               193\r\n 6           39.3               190\r\n 7           38.9               181\r\n 8           39.2               195\r\n 9           34.1               193\r\n10           42                 190\r\n# ... with 334 more rows\r\n\r\n# select variables beginning with \"bill\"\r\ndf %>% select(starts_with(\"bill\"))\r\n\r\n\r\n# A tibble: 344 x 2\r\n   bill_length_mm bill_depth_mm\r\n            <dbl>         <dbl>\r\n 1           39.1          18.7\r\n 2           39.5          17.4\r\n 3           40.3          18  \r\n 4           NA            NA  \r\n 5           36.7          19.3\r\n 6           39.3          20.6\r\n 7           38.9          17.8\r\n 8           39.2          19.6\r\n 9           34.1          18.1\r\n10           42            20.2\r\n# ... with 334 more rows\r\n\r\nfilter()\r\nThe filter() function allows you to subset rows based on variable attributes. In base R, there are multiple options for this. Say I wanted to subset just to Chinstrap penguins in df:\r\n\r\n\r\n# One option using subset()\r\nchinstrap_df = subset(df, species == \"Chinstrap\")\r\n\r\n# Another using just brackets (note the use of a comma at the end,\r\n# which indicates we want all the columns returned as well):\r\nchinstrap_df = df[df$species == \"Chinstrap\",]\r\n\r\n\r\n\r\nNote that I’m saving the result to a separate dataframe, but this can be inefficient when you have dozens of subsets at one. While you may want to do operations like this later on:\r\n\r\n\r\nmean(chinstrap_df$bill_length_mm, na.rm = T)\r\n\r\n\r\n[1] 48.83382\r\n\r\n… note that we can do the same thing without cluttering our R environment:\r\n\r\n\r\nmean(df$bill_length_mm[df$species == \"Chinstrap\"], na.rm = T)\r\n\r\n\r\n[1] 48.83382\r\n\r\nAlthough this is admittedly a bit cluttered. filter() cleans the subsetting up a bit:\r\n\r\n\r\ndf %>% filter(species == \"Chinstrap\")\r\n\r\n\r\n\r\nYou can also nest this inside another function, but we’ll get into alternatives to that with summarise():\r\n\r\n\r\nmean(filter(df, species == \"Chinstrap\")$bill_length_mm, na.rm = T)\r\n\r\n\r\n[1] 48.83382\r\n\r\nfilter() can also handle more complicated subsets as well:\r\n\r\n\r\n# Just Gentoo or Chinstrap Penguins\r\ndf %>% filter(species %in% c(\"Gentoo\", \"Chinstrap\"))\r\n\r\n# Male penguins with a minimum bill length\r\ndf %>% filter(sex == \"male\" & bill_length_mm > 40)\r\n\r\n# Male penguins OR penguins with minimum bill length\r\ndf %>% filter(sex == \"male\" | bill_length_mm > 40)\r\n\r\n\r\n\r\narrange()\r\nThe arrange() function is used to order the data. This is more useful when you have continuous variables with large numbers of values and you want to look at the extremes. This is super useful when you have country data and want to know which country has the highest or lowest of X variable.\r\nFor this example I’m going to use the gapminder country data, which is more appropriate for this example:\r\n\r\n\r\nlibrary(gapminder) #install the package if you need it\r\nglimpse(gapminder)\r\n\r\n\r\nRows: 1,704\r\nColumns: 6\r\n$ country   <fct> \"Afghanistan\", \"Afghanistan\", \"Afghanistan\", \"Afgh~\r\n$ continent <fct> Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, As~\r\n$ year      <int> 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 19~\r\n$ lifeExp   <dbl> 28.801, 30.332, 31.997, 34.020, 36.088, 38.438, 39~\r\n$ pop       <int> 8425333, 9240934, 10267083, 11537966, 13079460, 14~\r\n$ gdpPercap <dbl> 779.4453, 820.8530, 853.1007, 836.1971, 739.9811, ~\r\n\r\nSay you want to look at which country has the highest life expectancy. You can use arrange(), which defaults to arranging from lowest to highest, but you can switch this using desc():\r\n\r\n\r\ngapminder %>%\r\n  arrange(desc(lifeExp)) %>%\r\n  select(country,lifeExp,year) %>%\r\n  head()\r\n\r\n\r\n# A tibble: 6 x 3\r\n  country          lifeExp  year\r\n  <fct>              <dbl> <int>\r\n1 Japan               82.6  2007\r\n2 Hong Kong, China    82.2  2007\r\n3 Japan               82    2002\r\n4 Iceland             81.8  2007\r\n5 Switzerland         81.7  2007\r\n6 Hong Kong, China    81.5  2002\r\n\r\nOkay, great, Japan. But notice this data is arranged by country-year. That doesn’t makes sense. Let’s just look at highest life expectancy in the latest year in the data.\r\n\r\n\r\ngapminder %>%\r\n  filter(year == max(year)) %>%\r\n  arrange(desc(lifeExp)) %>% \r\n  head()\r\n\r\n\r\n# A tibble: 6 x 6\r\n  country          continent  year lifeExp       pop gdpPercap\r\n  <fct>            <fct>     <int>   <dbl>     <int>     <dbl>\r\n1 Japan            Asia       2007    82.6 127467972    31656.\r\n2 Hong Kong, China Asia       2007    82.2   6980412    39725.\r\n3 Iceland          Europe     2007    81.8    301931    36181.\r\n4 Switzerland      Europe     2007    81.7   7554661    37506.\r\n5 Australia        Oceania    2007    81.2  20434176    34435.\r\n6 Spain            Europe     2007    80.9  40448191    28821.\r\n\r\nYou can arrange() by several variables, too. Let’s say we want to arrange() by year and gdpPercap. This means you won’t have to use the filter() function\r\n\r\n\r\ngapminder %>%\r\n  arrange(desc(year),desc(gdpPercap)) %>%\r\n  head()\r\n\r\n\r\n# A tibble: 6 x 6\r\n  country          continent  year lifeExp       pop gdpPercap\r\n  <fct>            <fct>     <int>   <dbl>     <int>     <dbl>\r\n1 Norway           Europe     2007    80.2   4627926    49357.\r\n2 Kuwait           Asia       2007    77.6   2505559    47307.\r\n3 Singapore        Asia       2007    80.0   4553009    47143.\r\n4 United States    Americas   2007    78.2 301139947    42952.\r\n5 Ireland          Europe     2007    78.9   4109086    40676.\r\n6 Hong Kong, China Asia       2007    82.2   6980412    39725.\r\n\r\n#or by continent\r\ngapminder %>%\r\n  filter(year == max(year)) %>%\r\n  arrange(desc(continent),desc(gdpPercap)) %>%\r\n  select(year, country, continent, gdpPercap) %>%\r\n  head()\r\n\r\n\r\n# A tibble: 6 x 4\r\n   year country     continent gdpPercap\r\n  <int> <fct>       <fct>         <dbl>\r\n1  2007 Australia   Oceania      34435.\r\n2  2007 New Zealand Oceania      25185.\r\n3  2007 Norway      Europe       49357.\r\n4  2007 Ireland     Europe       40676.\r\n5  2007 Switzerland Europe       37506.\r\n6  2007 Netherlands Europe       36798.\r\n\r\nmutate()\r\nUse mutate() to add new variables (columns) to your dataframe. This is probably my most frequently used function in the tidyverse.\r\nReturning to our penguins dataframe df, note our weight measurement is in grams. In base R, if I wanted to create a mass in kilograms variable, it would look something like this:\r\n\r\n\r\ndf$body_mass_kg = df$body_mass_g/1000 # Every kg is 1000 g\r\n\r\n\r\n\r\nEasy enough for one variable, but a bit clunky when you want to create many. mutate() makes it a bit easier:\r\n\r\n\r\ndf %>% mutate(body_mass_kg = body_mass_g/1000)\r\n\r\n\r\n\r\nCool, but the real power is in being able to do this with multiple variables at once, and even using variables you just created to make new ones:\r\n\r\n\r\ndf %>%\r\n  mutate(bill_length_cm = bill_length_mm/10,\r\n         bill_depth_cm = bill_depth_mm/10,\r\n         bill_ratio = bill_length_cm/bill_depth_cm) %>% # Yes I know this would be the same with mm\r\n  arrange(desc(bill_ratio)) %>%\r\n  select(bill_ratio) %>%\r\n  head()\r\n\r\n\r\n# A tibble: 6 x 1\r\n  bill_ratio\r\n       <dbl>\r\n1       3.61\r\n2       3.51\r\n3       3.51\r\n4       3.49\r\n5       3.46\r\n6       3.45\r\n\r\nWe can also preview a bit of ggplot2 by piping our result directly into a plot, but that is beyond the scope of this particular bootcamp session:\r\n\r\n\r\ndf %>%\r\n  mutate(bill_length_cm = bill_length_mm/10,\r\n         bill_depth_cm = bill_depth_mm/10) %>%\r\n  ggplot(aes(x = bill_length_cm, y = bill_depth_cm, color = species)) + # ggplot uses + instead of %>%\r\n  geom_point() +\r\n  geom_smooth(method = \"lm\", se = F) +\r\n  geom_smooth(aes(group = 1), method = \"lm\", se = F, color = \"grey50\") +\r\n  theme_bw() +\r\n  labs(title = \"Relationship between Bill Length and Depth\",\r\n       subtitle = \"Simpson's Paradox!\",\r\n       x = \"Bill Length (cm)\", y = \"Bill Depth (cm)\")\r\n\r\n\r\n\r\n\r\nsummarise()\r\nFinally, we’ll focus on computing summary statistics with summarise() (same as summarize()), especially in conjunction with group_by(), which does computation within groups.\r\nIf we just wanted to get the average weight of all penguins in our dataset, we could do so very simply:\r\n\r\n\r\ndf %>% summarise(avg_mass = mean(body_mass_g, na.rm = T))\r\n\r\n\r\n# A tibble: 1 x 1\r\n  avg_mass\r\n     <dbl>\r\n1    4202.\r\n\r\nLike mutate(), we can compute multiple summary statistics at once:\r\n\r\n\r\ndf %>% \r\n  summarise(\r\n    avg_mass = mean(body_mass_g, na.rm = T),\r\n    med_mass = median(body_mass_g, na.rm = T),\r\n    max_mass = max(body_mass_g, na.rm = T),\r\n    min_mass = min(body_mass_g, na.rm = T),\r\n    n = n() # Gives number of observations (by group if paired with group_by())\r\n  )\r\n\r\n\r\n# A tibble: 1 x 5\r\n  avg_mass med_mass max_mass min_mass     n\r\n     <dbl>    <dbl>    <int>    <int> <int>\r\n1    4202.     4050     6300     2700   344\r\n\r\nAs we saw above, though, grouping matters. So perhaps we want to get the average mass by species of penguin. This can be done by using group_by() before summarise(). Let’s also combine this with another ggplot2 demonstration:\r\n\r\n\r\ndf %>%\r\n  group_by(species) %>%\r\n  summarise(avg_mass = mean(body_mass_g, na.rm = T)) %>%\r\n  ggplot(aes(x = species, y = avg_mass)) +\r\n  geom_bar(stat = 'identity') +\r\n  theme_bw() +\r\n  labs(title = \"Average Penguin Mass by Species\",\r\n       x = \"Species\", y = \"Average Mass (g)\")\r\n\r\n\r\n\r\n\r\nLike arrange(), we can also group_by() multiple variables. For example, we can look at the average mass by both species and sex:\r\n\r\n\r\ndf %>%\r\n  filter(!is.na(sex)) %>% # Remove missing sex\r\n  group_by(species, sex) %>%\r\n  summarise(avg_mass = mean(body_mass_g, na.rm = T)) %>%\r\n  ggplot(aes(x = species, y = avg_mass, fill = sex)) +\r\n  geom_bar(stat = 'identity', position = \"dodge\") +\r\n  theme_bw() +\r\n  labs(title = \"Average Penguin Mass by Species\",\r\n       x = \"Species\", y = \"Average Mass (g)\")\r\n\r\n\r\n\r\n\r\nNote that all grouping variables will continue to be available in the dataframe after summarise(), but non-grouping variables will not.\r\nacross()\r\nA recent addition to the tidyverse arsenal is the across() function, which helps shorten otherwise lengthy code. The purpose of across() is to perform the same function across multiple variables. Say, for example, I wanted to compute the mean of every numeric variable in my data. Without across(), I would have to write a separate line for every variable within summarise(). With across(), however, it gets much shorter:\r\n\r\n\r\ndf %>%\r\n  summarise(across(where(is.numeric), ~ mean(., na.rm = T)))\r\n\r\n\r\n# A tibble: 1 x 6\r\n  bill_length_mm bill_depth_mm flipper_length_mm body_mass_g  year\r\n           <dbl>         <dbl>             <dbl>       <dbl> <dbl>\r\n1           43.9          17.2              201.       4202. 2008.\r\n# ... with 1 more variable: body_mass_kg <dbl>\r\n\r\nObviously the year variable should be treated more as a factor than a numeric, but you get the point. Let’s break down exactly what is happening here: I’m summarising the entire dataset for variables that are numeric (where(is.numeric)), applying the mean() function and specifying that I want NAs removed.\r\nWe’re starting to get into more advanced notation here, so don’t worry if you need to slow down to understand it a bit more. across requires the second argument to be a function, so the tilde ~ is there to represent that the following statement should be evaluated as a function. Within the mean() function, we still need to tell R exactly what we are taking the mean of. In this case, the period . represents the values in each of the columns. This is common in tidyverse-style coding when values aren’t being explicitly defined within functions (ie after piping).\r\nYou can also use across() in conjunction with mutate(). For example, I could standardize all numeric variables to be on a 0-1 scale with the following:\r\n\r\n\r\ndf %>%\r\n  mutate(across(where(is.numeric), \r\n                ~ (. - min(., na.rm = T)) / (max(., na.rm = T) - min(., na.rm = T)) \r\n                )\r\n         ) %>%\r\n  select(where(is.numeric)) %>%\r\n  drop_na() %>% # Drops any rows with NAs in any column\r\n  head()\r\n\r\n\r\n# A tibble: 6 x 6\r\n  bill_length_mm bill_depth_mm flipper_length_mm body_mass_g  year\r\n           <dbl>         <dbl>             <dbl>       <dbl> <dbl>\r\n1          0.255         0.667             0.153       0.292     0\r\n2          0.269         0.512             0.237       0.306     0\r\n3          0.298         0.583             0.390       0.153     0\r\n4          0.167         0.738             0.356       0.208     0\r\n5          0.262         0.893             0.305       0.264     0\r\n6          0.247         0.560             0.153       0.257     0\r\n# ... with 1 more variable: body_mass_kg <dbl>\r\n\r\nA lot going on there, but you should notice that the structure is the same. I’m just passing a more complicated function where I take the value of each observation, substract from it the minimum of that variable, then divide it by the difference between the maximum and minimum values. I’m also using liberal use of parentheses, so it helps to line separate them when coding to make clear what end-parentheses corresponds to which open-parentheses.\r\nTest your knowledge\r\nFollow THIS LINK for a quick interactive knowledge check.\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-11-17-r-bootcamp-3-summarizing-data-with-the-tidyverse/r-bootcamp-3-summarizing-data-with-the-tidyverse_files/figure-html5/unnamed-chunk-23-1.png",
    "last_modified": "2021-11-29T12:24:37-08:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-11-14-r-bootcamp-2-reading-writing-and-manipulating-data/",
    "title": "R Bootcamp #2: Reading, Writing, and Manipulating Data",
    "description": "Using base R to perform common operations on external data",
    "author": [
      {
        "name": "Derek Holliday",
        "url": {}
      }
    ],
    "date": "2021-11-14",
    "categories": [
      "bootcamp"
    ],
    "contents": "\r\n\r\nContents\r\nVideo Summary\r\nGetting Data into R\r\nReading local files\r\nWorking directories\r\nFile types\r\n\r\nReading non-local files\r\n\r\nManipulating Data\r\nGetting to know your data\r\nExploring the data\r\nRecoding\r\nifelse()\r\nReverse Coding\r\nScales\r\n\r\n\r\nWriting Data\r\nTest your knowledge\r\n\r\nWelcome back! In this post, I’ll cover some common operations done while manipulating data in R using base R functions.\r\nVideo Summary\r\n\r\n\r\nGetting Data into R\r\nIn the last tutorial, we discussed one way pre-made data can be loaded into R: through packages. For non-toy examples, though, you will typically need to “read” data from an external file or site into your R environment in order to manipulate it. There are many ways to do this, and we’ll cover a few below.\r\nReading local files\r\nTypically, you will want to read files into R that already exist on your local computer. To do this, you need to know two things: where the file is located and what type of file it is.\r\nWorking directories\r\nRegarding file location, you will greatly benefit from keeping a consistent file organization system. One of the most worthwhile investments in grad school will be cloud storage. You should be able to completely destroy your computer and be back up and running with your files overnight. Typically, I keep one Dropbox folder per project with subfolders for data, code, writing, etc.\r\nBy default, R looks for and saves file in the working directory of the current R session. To see the current working directory for your session, enter the function getwd(). If you want to change your working directory, you can do so manually by entering the folder path in setwd(). For example, say I have a file I want to read in from the “r_maven” folder in my Dropbox. Given my own file pathing, my command may look like:\r\n\r\n\r\nsetwd(\"C:/Users/username/Dropbox/r_maven\") # Windows\r\nsetwd(\"/Users/username/Dropbox/r_maven\") # Mac\r\n\r\n\r\n\r\nYou can also set your working directory through RStudio using Session > Set Working Directory > Choose Directory. Selecting “Source file location” will set the working directory to where the current script is saved. You can also set the default working directory from Tools > Global Options. After that, you can use a period to reference your default directory in the file path. For example, if my default directory is set to “C:/Users/username”, I could access the same folder as above using:\r\n\r\n\r\nsetwd(\"./Dropbox/r_maven\")\r\n\r\n\r\n\r\nThese are the “classic” ways of setting the working directory, but modern alternatives exist. For example, you’ll notice I’m using what’s called an R Project, which automatically sets the working directory to the project folder. This is particularly useful when collaborating or using Github. You can learn more about R Projects here, but for now we’ll consider it a more advanced topic.\r\nFile types\r\nNow that we’ve set our working directory, we need to actually read in the data. There are many types of files you might work with, but the most common is a “.csv” file, which stands for “comma separated values.” R has a built-in function read.csv() for reading files like this. Assuming your file is located in your working directory, the following will read in the data and assign it to the object dat:\r\n\r\n\r\ndat = read.csv(\"filename.csv\")\r\n\r\n\r\n\r\nIf you check ?read.csv, you’ll notice the function returns a dataframe, so we can treat dat appropriately. Alternatively, many now prefer the read_csv() function from the readr package, which is documented to be significantly faster than base R’s read.csv().\r\nWhat if your data is saved as something other than a .csv file, though? You can find a solution for pretty much any file type. For Stata/SAS/SPSS files, I suggest functions from haven, such as read_dta(), read_sas(), and read_spss(). If you need data from a non-csv Excel file, the readxl and xlsx packages will be useful. For those with massive data files, fread() from data.table will be your best friend.\r\nReading non-local files\r\nSometimes we want to read files we haven’t downloaded locally, which is especially useful if we need to save space on our local drive. One way to read non-local files is simply using the appropriate read function with the link to the appropriate file.\r\nFor example, the New York Times datasets of COVID-19 cases and deaths. Looking at their documentation, I figure out the link for their nationally-aggregated results. I can read that file in below:\r\n\r\n\r\nnyt_cov = read.csv(\"https://raw.githubusercontent.com/nytimes/covid-19-data/master/us.csv\")\r\nhead(nyt_cov) # Print first 6 rows\r\n\r\n\r\n        date cases deaths\r\n1 2020-01-21     1      0\r\n2 2020-01-22     1      0\r\n3 2020-01-23     1      0\r\n4 2020-01-24     2      0\r\n5 2020-01-25     3      0\r\n6 2020-01-26     5      0\r\n\r\nAnother common way of getting data is querying an API. This is a fairly advanced topic, but I want you to know it’s an option. For example, King County, WA has a really well organized repository of precinct-level election results. I can get those results into an R-friendly format with the following:\r\n\r\n\r\n# The following two packages are necessary for API querying\r\nlibrary(httr)\r\nlibrary(jsonlite)\r\n\r\nres = GET(\"https://data.kingcounty.gov/resource/2824-fjrn.json\") # Save result of query to res\r\nking_wa = fromJSON(rawToChar(res$content)) # clean content and convert to dataframe\r\n\r\nhead(king_wa)\r\n\r\n\r\n     precinct                                     race leg cc cg\r\n1 SHL 32-0001 State of Washington Advisory Vote No. 32  32  1  7\r\n2 SHL 32-0001 State of Washington Advisory Vote No. 32  32  1  7\r\n3 SHL 32-0001 State of Washington Advisory Vote No. 32  32  1  7\r\n4 SHL 32-0001 State of Washington Advisory Vote No. 32  32  1  7\r\n5 SHL 32-0001 State of Washington Advisory Vote No. 32  32  1  7\r\n6 SHL 32-0001 State of Washington Advisory Vote No. 32  32  1  7\r\n  countergroup party       countertype sumofcount\r\n1        Total    NP Registered Voters        566\r\n2        Total    NP     Times Counted        418\r\n3        Total    NP Times Under Voted         42\r\n4        Total  <NA>          Repealed        182\r\n5        Total  <NA>        Maintained        194\r\n6        Total    NP  Times Over Voted          0\r\n\r\nAgain, there’s more going on here than we’re going to cover, such as the rawToChar() function and the fact that this API has a default limit of 1000 results returned per query, but you should know it exists as an option. Note we don’t need to set a working directory for external files.\r\nManipulating Data\r\nFor the next section, we’ll be using data from the 2016 ANES pilot, provided by Tyler Reny. Let’s read that into our environment now:\r\n\r\n\r\ndf = foreign::read.dta(\"http://tylerreny.github.io/data/anes_pilot_2016.dta\",\r\n                       convert.factors = F)\r\n\r\n\r\n\r\nNotice my use of foreign:: before the function we want to call. In some instances, you may want to use a function from a package without loading the entire package. The package-double colon-function syntax allows you to do that.\r\nGetting to know your data\r\nDownloading data sight unseen tends to mean we don’t know much about what’s inside. R has a few functions to help do so that you’ve already seen, such as:\r\n\r\n\r\ndim(df)\r\n\r\n\r\n[1] 1200  598\r\n\r\nYikes, that’s 1200 observations of 598 variables. Because of that, I’m not going to show the output of the functions below, since I’d be printing 598 lines (but see the video). Instead, know that names() returns a character vector of all the variable names in the dataframe. glimpse() from the dplyr package gives slightly more detail, giving you the variable names, the types of the variables, and the first few values.\r\n\r\n\r\nnames(df)\r\ndplyr::glimpse(df)\r\n\r\n\r\n\r\nExploring the data\r\nMost data, especially survey data, will come with a codebook to help guide your through how to interpret values associated with each variable. The code book for this particular dataset can be found here. For this exercise, we’ll focus on cleaning the demographic variables, which we can find in this chunk:\r\n\r\n\r\nnames(df)[218:238]\r\n\r\n\r\n [1] \"birthyr\"       \"gender\"        \"race\"          \"race_other\"   \r\n [5] \"educ\"          \"marstat\"       \"speakspanish\"  \"employ\"       \r\n [9] \"employ_t\"      \"faminc\"        \"faminc2\"       \"state\"        \r\n[13] \"votereg\"       \"pid3\"          \"pid7\"          \"ideo5\"        \r\n[17] \"newsint\"       \"pew_bornagain\" \"pew_churatd\"   \"religpew\"     \r\n[21] \"religpew_t\"   \r\n\r\nIf we want to dive into one particular variable, we can do so using head() and the variable selection syntax dataframe-dollar sign-variable:\r\n\r\n\r\nhead(df$birthyr)\r\n\r\n\r\n[1] 1995 1950 1973 1980 1978 1957\r\n\r\nLooks numeric, but we can confirm with class()\r\n\r\n\r\nclass(df$birthyr)\r\n\r\n\r\n[1] \"numeric\"\r\n\r\nWe can also use the table function to see how many times each year is in the data:\r\n\r\n\r\ntable(df$birthyr)\r\n\r\n\r\n\r\n1921 1924 1925 1926 1927 1930 1931 1932 1933 1934 1935 1936 1937 1938 \r\n   1    1    2    1    1    1    2    3    4    2    1    9    7   10 \r\n1939 1940 1941 1942 1943 1944 1945 1946 1947 1948 1949 1950 1951 1952 \r\n   6   12    8   10   14    8   16   12   16    9   16   18   20   24 \r\n1953 1954 1955 1956 1957 1958 1959 1960 1961 1962 1963 1964 1965 1966 \r\n  28   38   31   34   27   23   26   26   29   21   17   22   17    9 \r\n1967 1968 1969 1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 \r\n  14   18    8   13   10   24   34   20   24   21   25   26   16   24 \r\n1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 \r\n  20   22   19   18   17   21   22   24   27   26   20   22   19   20 \r\n1995 1996 1997 \r\n  13   17   14 \r\n\r\nsort(table(df$birthyr)) #Sort by number\r\n\r\n\r\n\r\n1921 1924 1926 1927 1930 1935 1925 1931 1934 1932 1933 1939 1937 1941 \r\n   1    1    1    1    1    1    2    2    2    3    4    6    7    8 \r\n1944 1969 1936 1948 1966 1938 1942 1971 1940 1946 1970 1995 1943 1967 \r\n   8    8    9    9    9   10   10   10   12   12   13   13   14   14 \r\n1997 1945 1947 1949 1979 1963 1965 1985 1996 1950 1968 1984 1983 1993 \r\n  14   16   16   16   16   17   17   17   17   18   18   18   19   19 \r\n1951 1974 1981 1991 1994 1962 1976 1986 1964 1982 1987 1992 1958 1952 \r\n  20   20   20   20   20   21   21   21   22   22   22   22   23   24 \r\n1972 1975 1980 1988 1977 1959 1960 1978 1990 1957 1989 1953 1961 1955 \r\n  24   24   24   24   25   26   26   26   26   27   27   28   29   31 \r\n1956 1973 1954 \r\n  34   34   38 \r\n\r\nYou can also look at a histogram to see how the years are distributed.\r\n\r\n\r\nhist(df$birthyr)\r\n\r\n\r\n\r\n\r\nThis is great, but say I want to create an age variable instead. To do that, we need to create a new variable, subtracting birth year from 2016 (since that’s when the survey was conducted):\r\n\r\n\r\ndf$age = 2016 - df$birthyr\r\n\r\n\r\n\r\nYou can check the new variable was created by looking at the name of the last variable in the dataset, where R puts new variables by default:\r\n\r\n\r\nnames(df)[ncol(df)]\r\n\r\n\r\n[1] \"age\"\r\n\r\nAnd we can look at a few properties of our newly created variable using a few functions you know and a few that are new:\r\n\r\n\r\nhist(df$age)\r\n\r\n\r\n\r\ntable(df$age)\r\nrange(df$age) # Min and Max values\r\nmean(df$age) # Average/Mean\r\nmedian(df$age) # Median\r\n\r\n\r\n\r\n19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 \r\n14 17 13 20 19 22 20 26 27 24 22 21 17 18 19 22 20 24 16 26 25 21 24 \r\n42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 \r\n20 34 24 10 13  8 18 14  9 17 22 17 21 29 26 26 23 27 34 31 38 28 24 \r\n65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 89 \r\n20 18 16  9 16 12 16  8 14 10  8 12  6 10  7  9  1  2  4  3  2  1  1 \r\n90 91 92 95 \r\n 1  2  1  1 \r\n[1] 19 95\r\n[1] 48.0625\r\n[1] 48\r\n\r\nOne of the nice things about this age variable is that there is no missing data (otherwise our mean/median functions would have returned an error). If you ever want to check for the prevalence of NA values, you can use is.na() (which returns a boolean vector the same length as the vector given to the function) in conjunction with a few other functions. Let’s do that using the ftobama variable, a feeling thermometer for President Obama, which I know has some NAs:\r\n\r\n\r\nany(is.na(df$ftobama)) # Are there ANY NA values in this vector?\r\n\r\n\r\n[1] TRUE\r\n\r\ntable(is.na(df$ftobama)) # How many?\r\n\r\n\r\n\r\nFALSE  TRUE \r\n 1198     2 \r\n\r\nwhich(is.na(df$ftobama)) # Where are there?\r\n\r\n\r\n[1]  62 742\r\n\r\nSo we know there are NA values in observations 62 and 742. We can check that using vector subsetting:\r\n\r\n\r\ndf$ftobama[61:63]\r\n\r\n\r\n[1] 88 NA 89\r\n\r\nRecoding\r\nSometimes survey data needs to be recoded to reflect the values we are interested. Let’s look at the distribution of the family income variable:\r\n\r\n\r\ntable(df$faminc)\r\n\r\n\r\n\r\n  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  31 \r\n 75 122 149 128 105  99  64  77  83  50  46  29  11   5   5   3   2 \r\n 97  98 \r\n146   1 \r\n\r\nSo there seems to be a bunch of values 1-16, but then 31? What about 97 and 98? Typically numbers like these reflect missing values in the data, but check the codebook to make sure. This is indeed the case for these values, so we want to recode them to reflect that. Look what would happen if we just took these values to be normal numeric values:\r\n\r\n\r\nmean(df$faminc)\r\n\r\n\r\n[1] 16.85\r\n\r\nhist(df$faminc)\r\n\r\n\r\n\r\n\r\nR is assuming these are just part of the continuous spectrum of values for faminc, which we know shouldn’t be the case, and it skews our summary statistics. Let’s create a new variable and recode it properly, overwriting the troublesome numbers with NA:\r\n\r\n\r\ndf$income_family = df$faminc # Create new variable\r\n\r\n# Overwrite values\r\ndf$income_family[df$income_family == 31] = NA\r\ndf$income_family[df$income_family == 97] = NA\r\ndf$income_family[df$income_family == 98] = NA\r\n\r\n# Check distribution\r\nhist(df$income_family)\r\n\r\n\r\n\r\n\r\n# Check mean (notice na.rm = T)\r\nmean(df$income_family, na.rm=T)\r\n\r\n\r\n[1] 5.611798\r\n\r\nThat’s better! What exactly is the code above doing when we overwrite the values? Remember our vector subsetting and assignment operators… we take the vector df$income_family, subset to the cases where the value is equal to a certain number, then assign NA to those cases.\r\nAlternatively, we can do this all in one step using the %in% operator:\r\n\r\n\r\ndf$income_family[df$income_family %in% c(31, 97, 98)] = NA\r\n\r\n\r\n\r\nYou can also write a function if you are going to use it a lot. This is way more complex than you need to know right now, but it’s an introduction to what functions do.\r\n\r\n\r\nrecode_missing = function(var_name, missing_vals){ # arguments the function takes\r\n  var_name[var_name %in% missing_vals] = NA # recode missing values\r\n  return(var_name) # return the new variable\r\n}\r\ndf$income_family = recode_missing(df$income_family, c(31, 97, 98)) \r\n\r\n\r\n\r\nifelse()\r\nNow we want to recode race, which is currently a single variable with discrete values for different racial groups, into a series of dummy variables (0/1) for each racial group. This can be achieved using ifelse(), which takes three arguments: test, yes, and no (in that order). Test is a logical test, yes is the value returned if the test is TRUE, and no is the value returned if the test is FALSE.\r\n\r\n\r\ndf$white <- ifelse(df$race == 1, 1, 0)\r\ntable(df$white) #always check your recoding afterwards against codebook\r\n\r\n\r\n\r\n  0   1 \r\n325 875 \r\n\r\ndf$black    <- ifelse(df$race == 2, 1, 0)\r\ndf$hispanic <- ifelse(df$race == 3, 1, 0)\r\ndf$asian    <- ifelse(df$race == 4, 1, 0)\r\n\r\n\r\n\r\nYou can chain multiple logic tests into your ifelse() statements. For example, if I wanted to create a dummy variable for white men, I could do the following:\r\n\r\n\r\ndf$white_man = ifelse(df$race == 1 & df$gender == 2, 1, 0)\r\n\r\n\r\n\r\nNote that for observations with NA values, ifelse() willl return NA instead of 1 or 0. Usually that’s fine.\r\nReverse Coding\r\nPartisanship is usually measured using a 7 point scale, which is the case for the pid7 variable. Let’s first check on NAs:\r\n\r\n\r\ntable(is.na(df$pid7))\r\n\r\n\r\n\r\nFALSE  TRUE \r\n 1145    55 \r\n\r\nLooks like we’ll have to get rid of those. One thing I have trouble with in the pid7 scale is whether 7 is strong Republican or strong Democrat. I’ll recode the data and come back to it months later and forget. So, I suggest renaming it by the direction of the scale. So if 7 is strong Republican, name the variable republican_pid7 or just republican and vice versa.\r\n\r\n\r\ndf$republican_pid7 = df$pid7\r\n\r\n\r\n\r\nI usually code all my variables in similar directions. If interested in exploring the effects of racial resentment on vote or attitudes towards Obama, for example, we would want the high values on the racial resentment scale to be more racially resentful, pid7 to be recoded with Republican as the high category, and ideology to be recoded so very conservative is the largest value. When you are looking at a regression, you will see that all are positive. Otherwise you have to remember how each is coded. This way is easier.\r\nYou will have to reverse code things all the time. Here is an easy way to do it.\r\n\r\n\r\ndf$democrat_pid7 = abs(df$pid7 - 8) #reverse code\r\n\r\n#step 1. How many unique values in the scale? Add one\r\nlength(table(df$pid7)) + 1 #this would be a more general form of that\r\n\r\n\r\n[1] 8\r\n\r\n#step 2. Double check that the new scale is, indeed, a mirror image of the old scale\r\ntable(dem7 = df$democrat_pid7, rep7 = df$republican_pid7)\r\n\r\n\r\n    rep7\r\ndem7   1   2   3   4   5   6   7\r\n   1   0   0   0   0   0   0 158\r\n   2   0   0   0   0   0 116   0\r\n   3   0   0   0   0 111   0   0\r\n   4   0   0   0 205   0   0   0\r\n   5   0   0 109   0   0   0   0\r\n   6   0 146   0   0   0   0   0\r\n   7 300   0   0   0   0   0   0\r\n\r\nYou can also write this trick into a function! But always double check that things were recoded correctly!\r\n\r\n\r\nreverse_code <- function(x){\r\n  vals <- length(table(x)) + 1\r\n  abs(x - vals)\r\n}\r\ndf$democrat_pid7 <- reverse_code(df$pid7)\r\n\r\n\r\n\r\nScales\r\nFinally, we want to create a racial resentment scale. Go back to the codebook and find rr1 through rr4. This is the racial resentment battery. You’ll notice that they are all likert scale questions coded from 1 to 5 with different values for missing data. Some are reverse coded so that most resentful is a higher value and some so that least resentful is a higher value. What you have to do is look at each one, check for missing data, see if you need to flip ordering of values or not to be consistent, and then combine them all into a scale by adding them together.\r\n\r\n\r\n# Special favors\r\ntable(df$rr1)\r\n\r\n\r\n\r\n  1   2   3   4   5   8 \r\n480 247 204 118 148   3 \r\n\r\ndf$rr1rc <- recode_missing(df$rr1, 8) #recode missing\r\ndf$rr1rc <- reverse_code(df$rr1rc) #reverse code\r\ntable(df$rr1rc)\r\n\r\n\r\n\r\n  1   2   3   4   5 \r\n148 118 204 247 480 \r\n\r\n\r\n# Work way out\r\ntable(df$rr2)\r\n\r\n\r\n\r\n  1   2   3   4   5   8 \r\n213 243 196 200 345   3 \r\n\r\ndf$rr2rc <- recode_missing(df$rr2, 8) #recode missing\r\ntable(df$rr2rc)\r\n\r\n\r\n\r\n  1   2   3   4   5 \r\n213 243 196 200 345 \r\n\r\n\r\n# Less than deserve\r\ntable(df$rr3)\r\n\r\n\r\n\r\n  1   2   3   4   5   8 \r\n165 178 315 212 327   3 \r\n\r\ndf$rr3rc <- recode_missing(df$rr3, 8) #recode missing\r\ntable(df$rr3rc)\r\n\r\n\r\n\r\n  1   2   3   4   5 \r\n165 178 315 212 327 \r\n\r\n\r\n# Try harder\r\ntable(df$rr4)\r\n\r\n\r\n\r\n  1   2   3   4   5   8 \r\n270 274 301 144 209   2 \r\n\r\ndf$rr4rc <- recode_missing(df$rr4, 8) #recode missing\r\ndf$rr4rc <- reverse_code(df$rr4rc) #reverse code\r\ntable(df$rr4rc)\r\n\r\n\r\n\r\n  1   2   3   4   5 \r\n209 144 301 274 270 \r\n\r\n\r\n#check correlation to ensure they are coded properly\r\n#if you have negative numbers, you miscoded one\r\ncor(cbind(df$rr1rc,df$rr2rc,df$rr3rc,df$rr4rc), use='complete.obs')\r\n\r\n\r\n          [,1]      [,2]      [,3]      [,4]\r\n[1,] 1.0000000 0.6242036 0.6071225 0.7349020\r\n[2,] 0.6242036 1.0000000 0.7642206 0.5554276\r\n[3,] 0.6071225 0.7642206 1.0000000 0.5444361\r\n[4,] 0.7349020 0.5554276 0.5444361 1.0000000\r\n\r\n\r\n#combine into scale (ask yourself why this math works)\r\ndf$rr_scale <- ((df$rr1rc + df$rr2rc + df$rr3rc + df$rr4rc) - 4)/16\r\nhist(df$rr_scale)\r\n\r\n\r\n\r\nrange(df$rr_scale, na.rm=T)\r\n\r\n\r\n[1] 0 1\r\n\r\nWriting Data\r\nSo far we’ve created new variables for age, income, and race. There is so much more we could do here… recode gender to be a 0/1 indicator for female, reverse code ideology, etc. We’ve done quite a bit, though, so we should save our changes by writing this file to a new csv that we can load later.\r\nThe process of writing to csv is very similar to that of reading in data. By default, the file will be written to your working directoy. If you want to write it elsewhere, just specify it in the path argument:\r\n\r\n\r\nwrite.csv(df, file = \"C:/Users/myname/Dropbox/r_maven/cleaned_anes.csv\")\r\n\r\n\r\n\r\nTest your knowledge\r\nFollow THIS LINK for a quick interactive knowledge check.\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-11-14-r-bootcamp-2-reading-writing-and-manipulating-data/r-bootcamp-2-reading-writing-and-manipulating-data_files/figure-html5/unnamed-chunk-13-1.png",
    "last_modified": "2021-11-16T19:55:10-08:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-11-09-r-bootcamp-1-the-basics/",
    "title": "R Bootcamp #1: The Basics",
    "description": "An introduction to basic R functions, data types, and structures",
    "author": [
      {
        "name": "Derek Holliday",
        "url": {}
      }
    ],
    "date": "2021-11-09",
    "categories": [
      "bootcamp"
    ],
    "contents": "\r\n\r\nContents\r\nStructure and Setup\r\nVideo Summary\r\nWhat is R?\r\nBasic R Commands\r\nAssignment\r\nMath\r\nVariables\r\nVectors\r\nNaming vectors\r\nManipulating vectors\r\n\r\nMatrices: 2-dimensional arrays of data\r\nSelecting objects from a 2 dimension array\r\n\r\nDataframes\r\nLists\r\n\r\nTest your knowledge\r\nAcknowledgements\r\n\r\n\r\nWelcome to R bootcamp! Over the next few posts, we will cover basic R functionality necessary for your growth as social scientists.\r\nStructure and Setup\r\nEach tutorial will focus on one facet of R programming and can consist of a number of resources. Some will be done in video format, others more as long-form written tutorials, and some with more interactive components (or a combination of the 3). They are designed so that you can complete them in one or two sittings (think of them as a class session). Tutorials may be created by more than one Maven/TA, so you have the opportunity to see different approaches and styles. You are encouraged to reach out to us if you ever get stuck, we’re here to help!\r\nIf you haven’t already, you should install R and RStudio.\r\nVideo Summary\r\n\r\n\r\nWhat is R?\r\nR is a programming language designed for statistical computing. One of its main draws is that R is free and open source, meaning it is openly available for modification and distribution. The result is an incredibly vibrant user base active in creating new and exciting ways to use the language. It also means online help is easy to come by! R is becoming more and more popular in academia and industry for data analysis… pretty much anything you can do in Python can be done in R and vice-versa.\r\nWhile you can run R code via the built-in graphical user interface (RGui), the dominant preference is using RStudio. RStudio is an integrated development environment (IDE) that gives you all the tools needed to program. The main benefit is the ability to write and test scripts on the fly without having to enter commands one at a time.\r\nFor a more detailed summary of navigating RStudio, watch the video provided with this tutorial.\r\nBasic R Commands\r\nNow for some basic functionalities within R. If you’ve had previous experience with R or any other programming language, this should be familiar to you and you can go through this quickly.\r\nAssignment\r\nR is an object oriented programming language, meaning the basic building block when coding is some object that has an associated value.\r\nTo assign a value to a variable, we use an assignment operator. <- is the most commonly used assignment operator amongst R users, but many who come from a more programming-oriented background (myself included) use =.\r\n\r\n\r\na <- 1 # assign the variable 'a' the value of 1\r\na # print\r\n\r\n\r\n[1] 1\r\n\r\nThe first line of code above makes the assignment, and the second of just entering a asks R to give you the value of that variable. The same thing works using =:\r\n\r\n\r\nb = 2\r\nb\r\n\r\n\r\n[1] 2\r\n\r\nMath\r\nR can be used as a calculator using both numbers and the variables you assign values to. R follows PEMDAS, but () are recommended for readability.\r\n\r\n\r\n5 + 6 # addition\r\n\r\n\r\n[1] 11\r\n\r\n9 - 3 # subtraction\r\n\r\n\r\n[1] 6\r\n\r\n6 / 10 # division\r\n\r\n\r\n[1] 0.6\r\n\r\n5 * 8 # multiplication\r\n\r\n\r\n[1] 40\r\n\r\n5 ^ 2 # exponentiation\r\n\r\n\r\n[1] 25\r\n\r\nsqrt(25) # square roots, etc...\r\n\r\n\r\n[1] 5\r\n\r\nNote the different structure of sqrt(). This is a function, where 25 is the value provided to the first argument of the function. We will get into more complex functions later, but is important you understand the language behind them. Also note you can perform multiple operations at once, but remember your order of operations!\r\n\r\n\r\n5 + 3 ^ 2 / 3 - 10\r\n\r\n\r\n[1] -2\r\n\r\n(5 + 3)^2 / (3 - 10)\r\n\r\n\r\n[1] -9.142857\r\n\r\nVariables\r\nVariables are the workhorse objects of R. They store whatever you give them (what we did above with a and b).\r\nThere are many naming conventions for variables, and it tends to depend on your personal style:\r\n\r\n\r\nsome_use_snake_case\r\nothers.use.periods\r\ngoogleUsesCamelCase\r\n\r\n\r\n\r\nThis is entirely a matter of preference. I tend to use snake case because many of the base R functions use periods and shouldn’t be overwritten (such as is.matrix()), but that isn’t unique to periods (for example, the read_dta() function from the haven package).\r\nWe can now perform operations using variables:\r\n\r\n\r\nx = 10\r\ny = 15\r\nx + y\r\n\r\n\r\n[1] 25\r\n\r\nOnce a variable is stored, it is kept in your system’s global environment until overwritten or you shut down your R session. Remember the values of a and b from above?\r\n\r\n\r\na + b\r\n\r\n\r\n[1] 3\r\n\r\nVariables don’t have to be numeric. For example, we can assign a character string to x, overwriting its previous value:\r\n\r\n\r\nx = 'This is a character string'\r\nx\r\n\r\n\r\n[1] \"This is a character string\"\r\n\r\nEither single or double quotations work, just be consistent. Now that we’ve overwritten the value of x, look at what happens when we try to mix types in a function:\r\n\r\n\r\nx + y\r\n\r\n\r\nError in x + y: non-numeric argument to binary operator\r\n\r\nYou should be wary of performing operations on mixed types, as they can lead to unexpected outcomes. R is a fairly lenient language… if it can do something, it’ll do it without warning you that something might be fishy.\r\nTo check what kind of variable you have, you can use class():\r\n\r\n\r\nclass(x)\r\n\r\n\r\n[1] \"character\"\r\n\r\nclass(y)\r\n\r\n\r\n[1] \"numeric\"\r\n\r\nAnother type of variable is a boolean. These take simple TRUE/FALSE values:\r\n\r\n\r\nmy_boolean = T\r\nmy_other_boolean = FALSE\r\n\r\nmy_boolean\r\n\r\n\r\n[1] TRUE\r\n\r\nmy_other_boolean\r\n\r\n\r\n[1] FALSE\r\n\r\nYou can use the single letters T/F and the written versions TRUE/FALSE interchangeably. Just make sure to NEVER assign a value to T or F unless you want to break something.\r\nVectors\r\nSo far we’ve worked with variables with only one object in them:\r\n\r\n\r\nlength(x) # returns number of objects inside a variable\r\n\r\n\r\n[1] 1\r\n\r\nThese are called scalars and are actually fairly rare in our day-to-day work, since we tend to want to perform operations on variables holding multiple objects. These variables are called vectors:\r\n\r\n\r\nmy_vector = c(1,2,3,4,5,6)\r\nmy_vector\r\n\r\n\r\n[1] 1 2 3 4 5 6\r\n\r\nclass(my_vector)\r\n\r\n\r\n[1] \"numeric\"\r\n\r\nlength(my_vector)\r\n\r\n\r\n[1] 6\r\n\r\nNotice that c() is a function that combines or concatenates objects together. Note that all the objects in a vector need to be the same class. Let’s see what happens when we combine character and numeric objects together:\r\n\r\n\r\nvector2 = c(1,2,3,'dog')\r\nvector2\r\n\r\n\r\n[1] \"1\"   \"2\"   \"3\"   \"dog\"\r\n\r\nclass(vector2)\r\n\r\n\r\n[1] \"character\"\r\n\r\nWhat did it do to the numeric elements? Note that it will ALWAYS default to ALL characters if you have a single non-numeric item in the vector.\r\nIn sum, you can have vectors of single type scalars:\r\n\r\n\r\nmy_numeric_vector = c(1,10,20,30,50,100)\r\nmy_character_vector = c('cool','this','is','a','character','vector')\r\nmy_boolean_vector = c(T,T,T,F,F,T)\r\n\r\n\r\n\r\nNaming vectors\r\nSometimes it can be useful to assign names to objects in vectors to keep track of values associated with certain things. Let’s say I want to assign batting averages to baseball players on the Los Angeles Dodgers. I’ll create a vector of batting averages, then assign names to the averages using the names() function:\r\n\r\n\r\nbatting_average = c(.338, .306, .278, .264)\r\nnames(batting_average) = c(\"Trea Turner\", \"Corey Seager\", \"Justin Turner\", \"Mookie Betts\")\r\nbatting_average\r\n\r\n\r\n  Trea Turner  Corey Seager Justin Turner  Mookie Betts \r\n        0.338         0.306         0.278         0.264 \r\n\r\nWhat if I want to reuse those names for other vectors, but don’t want to copy and paste them every time? You can create a vector of names and use that for assignment instead:\r\n\r\n\r\ngames_played = c(52, 95, 151, 122)\r\nplayer_names = c(\"Trea Turner\", \"Corey Seager\", \"Justin Turner\", \"Mookie Betts\")\r\nnames(games_played) = player_names\r\ngames_played\r\n\r\n\r\n  Trea Turner  Corey Seager Justin Turner  Mookie Betts \r\n           52            95           151           122 \r\n\r\nManipulating vectors\r\nVectors allow for some advanced calculations:\r\n\r\n\r\na <- c(1,2,3,4,5)\r\nb <- c(1,5,2,6,3)\r\nsum(a)\r\n\r\n\r\n[1] 15\r\n\r\nsum(b)\r\n\r\n\r\n[1] 17\r\n\r\nNotice what happens when you add these together (this is unique to vector based code!):\r\n\r\n\r\na + b\r\n\r\n\r\n[1]  2  7  5 10  8\r\n\r\nThe default R behavior is to perform element-wise operations: functions are applied to elements of the same position. Note that R will still perform operations on vectors of different lengths, but give a warning message and recycle elements from the shorter vector.\r\nSome other things you can do with vectors:\r\n\r\n\r\na > b  # Greater than\r\n\r\n\r\n[1] FALSE FALSE  TRUE FALSE  TRUE\r\n\r\na < b  # Less than\r\n\r\n\r\n[1] FALSE  TRUE FALSE  TRUE FALSE\r\n\r\na >= b # Greater than or equal to\r\n\r\n\r\n[1]  TRUE FALSE  TRUE FALSE  TRUE\r\n\r\na <= b # Less than or equal to\r\n\r\n\r\n[1]  TRUE  TRUE FALSE  TRUE FALSE\r\n\r\na == b # Equal to\r\n\r\n\r\n[1]  TRUE FALSE FALSE FALSE FALSE\r\n\r\na != b # Not equal to\r\n\r\n\r\n[1] FALSE  TRUE  TRUE  TRUE  TRUE\r\n\r\nYou can also locate items within vectors using bracket operators:\r\n\r\n\r\nb[2]       # second element\r\n\r\n\r\n[1] 5\r\n\r\nb[1:3]     # elements 1 through 3\r\n\r\n\r\n[1] 1 5 2\r\n\r\nb[c(2,4)]  # elements 2 and 4\r\n\r\n\r\n[1] 5 6\r\n\r\nb[-5]      # not element 5\r\n\r\n\r\n[1] 1 5 2 6\r\n\r\nb[-(2:3)]  # not elements 2 through 3\r\n\r\n\r\n[1] 1 6 3\r\n\r\nb[-c(2,4)] # not elements 2 and 4\r\n\r\n\r\n[1] 1 2 3\r\n\r\nYou can do some pretty advanced selections, too. Let’s say you want to pull out the values of every object in a vector that is positive:\r\n\r\n\r\nvec <- c(-2,-5,-7,2,5,-3,12)\r\nvec > 0 # notice the boolean vector returned\r\n\r\n\r\n[1] FALSE FALSE FALSE  TRUE  TRUE FALSE  TRUE\r\n\r\nvec[vec == 12] # this pulls out every value that corresponds to the argument\r\n\r\n\r\n[1] 12\r\n\r\nMatrices: 2-dimensional arrays of data\r\nMoving now from single vectors of data to 2 dimensional arrays (think of spreadsheets with rows and columns!) called matrices. Note that matrices are used frequently when you are doing statistical analyses. You won’t use explicitly use them very often, at least at first, with your own data analysis but you will be using them frequently in your statistics courses.\r\nLet’s create a 2x2 empty matrix:\r\n\r\n\r\nmatrix(nrow=2,ncol=2)\r\n\r\n\r\n     [,1] [,2]\r\n[1,]   NA   NA\r\n[2,]   NA   NA\r\n\r\nAt this point we should pause to discuss functions again. matrix is a function that creates a matrix and takes a number of arguments. Here, we are just providing values for two: nrow and ncol. To see the full list of arguments take by a function and how it works, simply type ?functionName into the console to display a help menu.\r\nYou can create a matrix with specific values:\r\n\r\n\r\nmatrix(data = c(1,2,3,4),nrow=2,ncol=2)\r\n\r\n\r\n     [,1] [,2]\r\n[1,]    1    3\r\n[2,]    2    4\r\n\r\nNotice it fills it in by column by default. You can fill it in the other way, by row:\r\n\r\n\r\nmatrix(data = c(1,2,3,4),nrow=2,ncol=2,byrow=T)\r\n\r\n\r\n     [,1] [,2]\r\n[1,]    1    2\r\n[2,]    3    4\r\n\r\nLet’s do a bigger matrix:\r\n\r\n\r\nmatrix(1:28,nrow=4)\r\n\r\n\r\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7]\r\n[1,]    1    5    9   13   17   21   25\r\n[2,]    2    6   10   14   18   22   26\r\n[3,]    3    7   11   15   19   23   27\r\n[4,]    4    8   12   16   20   24   28\r\n\r\nNotice that I don’t need to tell it number of columns because it will calculate how many columns needed to fill in 4 rows with 28 objects. What happens if I misspecify?\r\n\r\n\r\nmyMatrix <- matrix(1:25,nrow=4)\r\nmyMatrix\r\n\r\n\r\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7]\r\n[1,]    1    5    9   13   17   21   25\r\n[2,]    2    6   10   14   18   22    1\r\n[3,]    3    7   11   15   19   23    2\r\n[4,]    4    8   12   16   20   24    3\r\n\r\nNotice that IT WILL STILL CREATE THE MATRIX but will return an error. Look at what it does to the extra values that weren’t specified. If you mess up and mis-specify the matrix and don’t pay attention, you can create grave errors this way.\r\nYou can give the matrix rownames and column names:\r\n\r\n\r\nrownames(myMatrix) <- c('row1','row2','row3','row4')\r\ncolnames(myMatrix) <- c('a','b','c','d','e','f','g')\r\nmyMatrix\r\n\r\n\r\n     a b  c  d  e  f  g\r\nrow1 1 5  9 13 17 21 25\r\nrow2 2 6 10 14 18 22  1\r\nrow3 3 7 11 15 19 23  2\r\nrow4 4 8 12 16 20 24  3\r\n\r\nYou can add rows and columns to the matrix using two useful commands rbind and cbind:\r\n\r\n\r\nrow5 <- 1:7\r\nrbind(myMatrix,row5)\r\n\r\n\r\n     a b  c  d  e  f  g\r\nrow1 1 5  9 13 17 21 25\r\nrow2 2 6 10 14 18 22  1\r\nrow3 3 7 11 15 19 23  2\r\nrow4 4 8 12 16 20 24  3\r\nrow5 1 2  3  4  5  6  7\r\n\r\nNote what happens after you add that, though:\r\n\r\n\r\nmyMatrix\r\n\r\n\r\n     a b  c  d  e  f  g\r\nrow1 1 5  9 13 17 21 25\r\nrow2 2 6 10 14 18 22  1\r\nrow3 3 7 11 15 19 23  2\r\nrow4 4 8 12 16 20 24  3\r\n\r\nIt isn’t permanently added until you save it:\r\n\r\n\r\nmyMatrix <- rbind(myMatrix,row5)\r\nmyMatrix\r\n\r\n\r\n     a b  c  d  e  f  g\r\nrow1 1 5  9 13 17 21 25\r\nrow2 2 6 10 14 18 22  1\r\nrow3 3 7 11 15 19 23  2\r\nrow4 4 8 12 16 20 24  3\r\nrow5 1 2  3  4  5  6  7\r\n\r\nLet’s add a column now:\r\n\r\n\r\nh <- c(1,2,3,4,5)\r\nmyMatrix <- cbind(myMatrix,h)\r\nmyMatrix\r\n\r\n\r\n     a b  c  d  e  f  g h\r\nrow1 1 5  9 13 17 21 25 1\r\nrow2 2 6 10 14 18 22  1 2\r\nrow3 3 7 11 15 19 23  2 3\r\nrow4 4 8 12 16 20 24  3 4\r\nrow5 1 2  3  4  5  6  7 5\r\n\r\nSelecting objects from a 2 dimension array\r\nYou can use bracket operators to select objects from a 2-dimensional array as well. You just need to specify the row and column in this format matrix[row,column]\r\n\r\n\r\nmyMatrix[1,2] # row 1, column 2\r\n\r\n\r\n[1] 5\r\n\r\nmyMatrix[1,] # return EVERYTHING in row 1\r\n\r\n\r\n a  b  c  d  e  f  g  h \r\n 1  5  9 13 17 21 25  1 \r\n\r\nmyMatrix[,2] # return EVERYTHING in column 2\r\n\r\n\r\nrow1 row2 row3 row4 row5 \r\n   5    6    7    8    2 \r\n\r\nOr you can be more advanced. Let’s select row 1 and 5 for column 2 and 4:\r\n\r\n\r\nmyMatrix[c(1,5),c(2,4)]\r\n\r\n\r\n     b  d\r\nrow1 5 13\r\nrow5 2  4\r\n\r\nOr rows 1 through 4 of columns 2 through 4:\r\n\r\n\r\nmyMatrix[1:4,2:4]\r\n\r\n\r\n     b  c  d\r\nrow1 5  9 13\r\nrow2 6 10 14\r\nrow3 7 11 15\r\nrow4 8 12 16\r\n\r\nYou can do calculations with matrices:\r\n\r\n\r\nmyMatrix * 2\r\n\r\n\r\n     a  b  c  d  e  f  g  h\r\nrow1 2 10 18 26 34 42 50  2\r\nrow2 4 12 20 28 36 44  2  4\r\nrow3 6 14 22 30 38 46  4  6\r\nrow4 8 16 24 32 40 48  6  8\r\nrow5 2  4  6  8 10 12 14 10\r\n\r\nmyMatrix / 2\r\n\r\n\r\n       a   b   c   d    e    f    g   h\r\nrow1 0.5 2.5 4.5 6.5  8.5 10.5 12.5 0.5\r\nrow2 1.0 3.0 5.0 7.0  9.0 11.0  0.5 1.0\r\nrow3 1.5 3.5 5.5 7.5  9.5 11.5  1.0 1.5\r\nrow4 2.0 4.0 6.0 8.0 10.0 12.0  1.5 2.0\r\nrow5 0.5 1.0 1.5 2.0  2.5  3.0  3.5 2.5\r\n\r\nmyMatrix * myMatrix # This is element-wise\r\n\r\n\r\n      a  b   c   d   e   f   g  h\r\nrow1  1 25  81 169 289 441 625  1\r\nrow2  4 36 100 196 324 484   1  4\r\nrow3  9 49 121 225 361 529   4  9\r\nrow4 16 64 144 256 400 576   9 16\r\nrow5  1  4   9  16  25  36  49 25\r\n\r\nt(myMatrix) # transpose\r\n\r\n\r\n  row1 row2 row3 row4 row5\r\na    1    2    3    4    1\r\nb    5    6    7    8    2\r\nc    9   10   11   12    3\r\nd   13   14   15   16    4\r\ne   17   18   19   20    5\r\nf   21   22   23   24    6\r\ng   25    1    2    3    7\r\nh    1    2    3    4    5\r\n\r\nIf you want to do actual matrix multiplication, you need to use the special matrix multiplication operator %*%\r\n\r\n\r\nmyMatrix %*% t(myMatrix)\r\n\r\n\r\n     row1 row2 row3 row4 row5\r\nrow1 1632 1099 1191 1283  481\r\nrow2 1099 1149 1224 1299  339\r\nrow3 1191 1224 1307 1390  372\r\nrow4 1283 1299 1390 1481  405\r\nrow5  481  339  372  405  165\r\n\r\nDataframes\r\nThe next format we’ll learn is the data frame. This is how you will work with data almost all of the time you are doing statistical analyses. Think again of the spreadsheet where you have rows (observations) and columns (variables). Dataframes are different than matrices because they can hold different types of data. One column can be numeric, another character, and another boolean.\r\nImportant to note here that there is a ‘tidy’ version of dataframes called tibbles, which has built-in differences for viewing and stricter subsetting functionality. You will learn more about that in future lessons.\r\nTo work with a sample dataframe let’s install the package palmerpenguins so that we can work with their toy dataset.\r\n\r\n\r\n#install.packages('palmerpenguins') if you need to\r\nlibrary(palmerpenguins) #load the package and datasets\r\n\r\n\r\n\r\nIf you ever want to know what datasets a package loads, you can use the following:\r\n\r\n\r\ndata(package = \"palmerpenguins\")\r\n\r\n\r\n\r\nIn this case, we get two dataframes: penguins and penguins_raw.\r\nThere are some helper functions in R to help you look at a dataframe. The first, which will be helpful at first but I encourage you to not use frequently is View()\r\n\r\n\r\nView(penguins)\r\n\r\n\r\n\r\nUse these instead:\r\n\r\n\r\nhead(penguins) #looks at the first 6 rows\r\ntail(penguins) #looks at last 6 rows\r\nstr(penguins) #shows what each variable is\r\nsummary(penguins) #summarises each variable\r\n\r\n\r\n\r\nHow do you create your own dataframe?\r\n\r\n\r\nmyDataFrame <- data.frame(x = rnorm(10),\r\n                          y = rnorm(10))\r\nmyDataFrame\r\n\r\n\r\n            x           y\r\n1   0.7422935  0.01915408\r\n2  -0.6393958 -1.07390674\r\n3  -0.3553513 -0.70612467\r\n4   0.9717347 -0.66081543\r\n5   0.3951876  1.54822209\r\n6   0.3399082 -1.35654867\r\n7  -0.7663295 -0.24744880\r\n8   1.4427279 -0.77805014\r\n9   1.0579099 -0.46334326\r\n10  0.1759219  0.97311272\r\n\r\nA few things are happening here. I am creating a dataframe with 2 columns, x and y. Each consists of 10 random values from a standard normal distribution, that is what the rnorm() function does. Therefore it has 10 rows. You can look at the size of the dataframe with the dim() function or count the rows and columsn with the nrow() and ncol() functions. Note that your dataframe will look different than mine becuase you will be drawing different random numbers. This is okay! For consistency, you can use set.seed()\r\n\r\n\r\ndim(myDataFrame)\r\n\r\n\r\n[1] 10  2\r\n\r\nncol(myDataFrame)\r\n\r\n\r\n[1] 2\r\n\r\nnrow(myDataFrame)\r\n\r\n\r\n[1] 10\r\n\r\nYou select elements the same way as with matrices, but there are some additional operators for dataframes:\r\n\r\n\r\nmyDataFrame[1,2] #first row, second column\r\n\r\n\r\n[1] 0.01915408\r\n\r\nLet’s say you want to just look at the objects in column 1. There are four basic ways to do this (and probably more!)\r\n\r\n\r\nmyDataFrame[,1] # first column\r\nmyDataFrame[,'x'] # column named x\r\nmyDataFrame$x # column named x (most common)\r\nmyDataFrame[['x']] # column named x\r\n\r\n\r\n\r\nLists\r\nLast, but not least, lists are like file drawers cabinets where each object in the list (a drawer) can hold whatever it wants. Here’s an example:\r\n\r\n\r\nmyList <- vector('list',3) #this is a 3 object list, or a three drawer filed cabinet\r\nmyList\r\n\r\n\r\n[[1]]\r\nNULL\r\n\r\n[[2]]\r\nNULL\r\n\r\n[[3]]\r\nNULL\r\n\r\nLet’s add some stuff to the drawers:\r\n\r\n\r\nmyList[[1]] <- myDataFrame\r\nmyList[[2]] <- c('these','are','a','few', 'of', 'my', 'favorite', 'things')\r\nmyList[[3]] <- myMatrix\r\n\r\n\r\n\r\nThe first drawer now has our dataframe, the second a character vector, and the third a matrix. When you start working a lot with packages, you will see that packages often return objects to you in lists.\r\nNotice that you subset lists using the double brackets!\r\nIf you want to access a particular observation of a particular item in your list, you can do so. For example, let’s select the 2nd observation of the second element in the list:\r\n\r\n\r\nmyList[[3]][2,3]\r\n\r\n\r\n[1] 10\r\n\r\nTest your knowledge\r\nFollow THIS LINK to an interactive application to test the skills you learned in this lesson.\r\nAcknowledgements\r\nThis material (and much of the subsequent material) borrows from the work done by many before me. I’m especially grateful to Tyler Reny (Claremont Graduate University) and Justin Esarey (Wake Forest) for R resources and lessons.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2021-11-16T19:51:16-08:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-10-31-external-resources-for-r-beginners/",
    "title": "External Resources for R Beginners",
    "description": "A collection of R resources from around the coding world.",
    "author": [
      {
        "name": "Derek Holliday",
        "url": {}
      }
    ],
    "date": "2021-10-31",
    "categories": [
      "resources"
    ],
    "contents": "\r\nAs mavens, we will provide you with custom resources and tutorials tailored to your needs as political science graduate students. However, much of learning R is experimenting with multiple learning styles and pulling from different sources, so we want to introduce you to a few external resources we consider to be (1) high in quality and (2) relevant to your particular needs. All of these resources are free (with the exception of one). No one person learns R in the same was as another, and that’s part of the fun!\r\nTraditional Courses\r\nMany people find the traditional university course structure to be good for personal accountability. There are a number of intro to R courses online that fit this description:\r\nJohns Hopkins Data Science: Foundations using R Specialization (via coursera).\r\nHarvard Statistics and R (via edX, Life Science focus but the earlier parts are still a good introduction)\r\ncodecademy’s Learn R (requires a subscription, but slightly more interactive than the other courses)\r\nVideos and Books\r\nA slightly more hands-off approach, these resources give you a number of videos and examples you can pick and choose between and explore at your own pace:\r\nR for Data Science aka “The Bible” written by Hadley Wickham and Garrett Grolemund (you’ll be seeing those names quite a bit), this is the definitive source for a “tidy” textbook introduction R for our purposes.\r\nRStudio Primers written by the folks over at RStudio themselves, so you get the best practices straight from the source.\r\nSICSS Boot Camp for an option in between a true course and pick-and-choose video options.\r\nInteractive Materials\r\nOne of the greatest pedagogical advancements for R in the past few years is the availability of within-IDE tutorials for R beginners. You can boot up RStudio, load a lesson via one of these packages, and just follow directions from there, so you are truly able to learn while doing:\r\nKosuke Imai’s Quantitative Social Science: An Introduction via swirl is especially good with the introductory courses, and best used as a prerequisite to the materials that follow.\r\nSeo-young Silvia Kim’s introduction to the tidyverse via swirl is an amazing resource for beginners looking to tidy their approach to R.\r\nIt is also worth noting that swirl itself has its own courses, but they haven’t been updated for a few years.\r\nTwitter\r\nTwitter provides a great place to keep up with the latest and greatest in R tutorials, packages, and advancements. There are too many amazing accounts to list here, but I will suggest following We are R-Ladies, Hadley Wickham, and Julia Silge as active R Twitter users.\r\nA Closing Word\r\nAs new acolytes of R, you should be familiar that there is an ongoing boycott of a certain provider of R resources that we have purposefully left off this list. You should be aware that the boycott exists and can learn about the reasons why here.\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-10-31-external-resources-for-r-beginners/rresources.png",
    "last_modified": "2021-10-31T20:02:49-07:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-10-25-welcome-post/",
    "title": "Welcome Post",
    "description": "Our first post!",
    "author": [
      {
        "name": "Derek Holliday",
        "url": {}
      }
    ],
    "date": "2021-10-25",
    "categories": [
      "announcements"
    ],
    "contents": "\r\nWelcome! This page is where posts will be indexed. These will include videos and guides created by mavens and lists of external resources we have found useful.\r\nHello World\r\n\r\n\r\n",
    "preview": "posts/2021-10-25-welcome-post/HelloWorld.svg",
    "last_modified": "2021-10-25T16:30:39-07:00",
    "input_file": {}
  }
]
